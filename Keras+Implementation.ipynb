{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Masking, Dense\n",
    "from keras.layers.recurrent import LSTM\n",
    "\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import tensorflow as Th\n",
    "\n",
    "import random\n",
    "import math\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib import style\n",
    "\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "\n",
    "def read_file(dataset_path):\n",
    "    seqs_by_student = {}\n",
    "    problem_ids = {}\n",
    "    next_problem_id = 0\n",
    "    with open(dataset_path, 'r') as f:\n",
    "        for line in f:\n",
    "            student, problem, is_correct = line.strip().split(' ')\n",
    "            student = int(student)\n",
    "            if student not in seqs_by_student:\n",
    "                seqs_by_student[student] = []\n",
    "            if problem not in problem_ids:\n",
    "                problem_ids[problem] = next_problem_id\n",
    "                next_problem_id += 1\n",
    "            seqs_by_student[student].append((problem_ids[problem], int(is_correct == '1')))\n",
    "    \n",
    "    sorted_keys = sorted(seqs_by_student.keys())\n",
    "    return [seqs_by_student[k] for k in sorted_keys], next_problem_id\n",
    "\n",
    "\n",
    "def load_dataset(dataset, split_file):\n",
    "    seqs, num_skills = read_file(dataset)\n",
    "    \n",
    "    with open(split_file, 'r') as f:\n",
    "        student_assignment = f.read().split(' ')\n",
    "    \n",
    "    print(seqs)\n",
    "    training_seqs = [seqs[i] for i in xrange(0, len(seqs)) if student_assignment[i] == '1']\n",
    "    testing_seqs = [seqs[i] for i in xrange(0, len(seqs)) if student_assignment[i] == '0']\n",
    "\n",
    "def main():\n",
    "    \n",
    "    dataset = '/Users/subleenkaur/Downloads/2012-2013-data-with-predictions-4-final/my_assistments.txt'\n",
    "    split_file = '/Users/subleenkaur/Downloads/2012-2013-data-with-predictions-4-final/my_assistments_split.txt'\n",
    "    hidden_units = 128\n",
    "    batch_size = 5\n",
    "    time_window = 100\n",
    "    epochs = 50\n",
    "\n",
    "    model_file = dataset + '.model_weights'\n",
    "    history_file = dataset + '.history'\n",
    "    preds_file = dataset + '.preds'\n",
    "\n",
    "    overall_loss = [0.0]\n",
    "    preds = []\n",
    "    history = []\n",
    "    \n",
    "    training_seqs = ['1','2','4']\n",
    "    testing_seqs = ['3','5']\n",
    "    \n",
    "    print(type(overall_loss))\n",
    "\n",
    "    num_skills = 3\n",
    "    training_seqs = len(training_seqs)\n",
    "    testing_seqs = len(testing_seqs)\n",
    "    \n",
    "    # load dataset\n",
    "    #training_seqs, testing_seqs, num_skills = load_dataset(dataset, split_file)\n",
    "    #print \"Training Sequences: %d\" % len(training_seqs)\n",
    "    #print \"Testing Sequences: %d\" % len(testing_seqs)\n",
    "    #print \"Number of skills: %d\" % num_skills\n",
    "    \n",
    "    def loss_function(y_true, y_pred):\n",
    "        skill = y_true[:,:,0:num_skills]\n",
    "        obs = y_true[:,:,num_skills]\n",
    "        rel_pred = Th.reduce_sum(y_pred * skill, 2)\n",
    "        \n",
    "        # keras implementation does a mean on the last dimension (axis=-1) which\n",
    "        # it assumes is a singleton dimension. But in our context that would\n",
    "        # be wrong.\n",
    "        return K.binary_crossentropy(rel_pred, obs)\n",
    "    \n",
    "    # build model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # ignore padding\n",
    "    model.add(Masking(-1.0, batch_input_shape=(batch_size, time_window, 3*2)))\n",
    "\n",
    "    # lstm configured to keep states between batches\n",
    "    model.add(LSTM(input_dim = num_skills*2, \n",
    "                   output_dim = hidden_units, \n",
    "                   return_sequences=True,\n",
    "                   batch_input_shape=(batch_size, time_window, 3*2),\n",
    "                   stateful = True\n",
    "    ))\n",
    "    \n",
    "    # readout layer. TimeDistributedDense uses the same weights for all\n",
    "    # time steps.\n",
    "    model.add(TimeDistributed(Dense(input_dim = hidden_units, \n",
    "        output_dim = num_skills, activation='sigmoid')))\n",
    "   \n",
    "\n",
    "\n",
    "    # optimize with rmsprop which dynamically adapts the learning\n",
    "    # rate of each weight.\n",
    "    model.compile(loss=loss_function,optimizer='rmsprop')\n",
    "  \n",
    "\n",
    "    # training function\n",
    "    def trainer(X, Y):\n",
    "        print(model.train_on_batch(X,Y))\n",
    "        val = np.asscalar(model.train_on_batch(X,Y))\n",
    "        overall_loss[0] += val\n",
    "  \n",
    "\n",
    "    # prediction\n",
    "    def predictor(X, Y):\n",
    "        batch_activations = model.predict_on_batch(X)\n",
    "        skill = Y[:,:,0:num_skills]\n",
    "        obs = Y[:,:,num_skills]\n",
    "        y_pred = np.squeeze(np.array(batch_activations))\n",
    "        \n",
    "        rel_pred = np.sum(y_pred * skill, axis=2)\n",
    "        \n",
    "        for b in xrange(0, X.shape[0]):\n",
    "            for t in xrange(0, X.shape[1]):\n",
    "                if X[b, t, 0] == -1.0:\n",
    "                    continue\n",
    "                preds.append((rel_pred[b][t], obs[b][t]))\n",
    "    \n",
    "    \n",
    "    \n",
    "    # call when prediction batch is finished\n",
    "    # resets LSTM state because we are done with all sequences in the batch\n",
    "    def finished_prediction_batch(percent_done):\n",
    "        model.reset_states()\n",
    "    \n",
    "    \n",
    "    # similiar to the above\n",
    "    def finished_batch(percent_done):\n",
    "        print \"(%4.3f %%) %f\" % (percent_done, overall_loss[0])\n",
    "        model.reset_states()\n",
    "    \n",
    "    \n",
    "    # run the model\n",
    "    for e in xrange(0, epochs):\n",
    "        model.reset_states()\n",
    "        \n",
    "        # train\n",
    "        run_func(training_seqs, num_skills, trainer, batch_size, time_window, finished_batch)\n",
    "        \n",
    "        model.reset_states()\n",
    "        \n",
    "        # test\n",
    "        run_func(testing_seqs, num_skills, predictor, batch_size, time_window, finished_prediction_batch)\n",
    "        \n",
    "        # compute AUC\n",
    "        auc = roc_auc_score([p[1] for p in preds], [p[0] for p in preds])\n",
    "        \n",
    "        # log\n",
    "        history.append((overall_loss[0], auc))\n",
    "        \n",
    "        # save model\n",
    "        model.save_weights(model_file, overwrite=True)\n",
    "        print \"==== Epoch: %d, Test AUC: %f\" % (e, auc)\n",
    "        \n",
    "        # reset loss\n",
    "        overall_loss[0] = 0.0\n",
    "        \n",
    "        # save predictions and plot graph\n",
    "        with open(preds_file, 'w') as f:\n",
    "            f.write('was_heldout\\tprob_recall\\tstudent_recalled\\n')\n",
    "            for pred in preds:\n",
    "                f.write('1\\t%f\\t%d\\n' % (pred[0], pred[1]))\n",
    "        \n",
    "        with open(history_file, 'w') as f:\n",
    "            for h in history:\n",
    "                f.write('\\t'.join([str(he) for he in h]))\n",
    "                f.write('\\n')\n",
    "        \n",
    "        # clear preds\n",
    "        preds = []\n",
    "        \n",
    "def run_func(seqs, num_skills, f, batch_size, time_window, batch_done = None):\n",
    "    \n",
    "    print('seqs')\n",
    "    print(seqs)\n",
    "    seqs =[[(0, 1), (1, 1), (2, 0)], \n",
    "           [(0, 0), (1, 1), (2, 1)], \n",
    "           [(0, 1), (1, 0), (2, 1)], \n",
    "           [(0, 1), (1, 1), (1, 1)], \n",
    "           [(0, 0), (1, 0), (2, 1)]]\n",
    "    \n",
    "    assert(min([len(s) for s in seqs]) > 0)\n",
    "    \n",
    "    # randomize samples\n",
    "    seqs = seqs[:]\n",
    "    random.shuffle(seqs)\n",
    "    \n",
    "    processed = 0\n",
    "    for start_from in xrange(0, len(seqs), batch_size):\n",
    "       end_before = min(len(seqs), start_from + batch_size)\n",
    "       x = []\n",
    "       y = []\n",
    "       for seq in seqs[start_from:end_before]:\n",
    "           x_seq = []\n",
    "           y_seq = []\n",
    "           xt_zeros = [0 for i in xrange(0, num_skills*2)]\n",
    "           ct_zeros = [0 for i in xrange(0, num_skills+1)]\n",
    "           xt = xt_zeros[:]\n",
    "           for skill, is_correct in seq:\n",
    "               x_seq.append(xt)\n",
    "               \n",
    "               ct = ct_zeros[:]\n",
    "               ct[skill] = 1\n",
    "               ct[num_skills] = is_correct\n",
    "               y_seq.append(ct)\n",
    "               \n",
    "               # one hot encoding of (last_skill, is_correct)\n",
    "               pos = skill * 2 + is_correct\n",
    "               xt = xt_zeros[:]\n",
    "               xt[pos] = 1\n",
    "               \n",
    "           x.append(x_seq)\n",
    "           y.append(y_seq)\n",
    "       \n",
    "       maxlen = max([len(s) for s in x])\n",
    "       maxlen = round_to_multiple(maxlen, time_window)\n",
    "       # fill up the batch if necessary\n",
    "       if len(x) < batch_size:\n",
    "            for e in xrange(0, batch_size - len(x)):\n",
    "                x_seq = []\n",
    "                y_seq = []\n",
    "                for t in xrange(0, time_window):\n",
    "                    x_seq.append([-1.0 for i in xrange(0, num_skills*2)])\n",
    "                    y_seq.append([0.0 for i in xrange(0, num_skills+1)])\n",
    "                x.append(x_seq)\n",
    "                y.append(y_seq)\n",
    "        \n",
    "       X = pad_sequences(x, padding='post', maxlen = maxlen, dim=num_skills*2, value=-1.0)\n",
    "       Y = pad_sequences(y, padding='post', maxlen = maxlen, dim=num_skills+1, value=-1.0)\n",
    "        \n",
    "       for t in xrange(0, maxlen, time_window):\n",
    "           f(X[:,t:(t+time_window),:], Y[:,t:(t+time_window),:])\n",
    "           \n",
    "       processed += end_before - start_from\n",
    "       \n",
    "       # reset the states for the next batch of sequences\n",
    "       if batch_done:\n",
    "           batch_done((processed * 100.0) / len(seqs))\n",
    "        \n",
    "def round_to_multiple(x, base):\n",
    "    return int(base * math.ceil(float(x)/base))\n",
    "\n",
    "# https://groups.google.com/forum/#!msg/keras-users/7sw0kvhDqCw/QmDMX952tq8J\n",
    "def pad_sequences(sequences, maxlen=None, dim=1, dtype='int32',\n",
    "    padding='pre', truncating='pre', value=0.):\n",
    "    '''\n",
    "        Override keras method to allow multiple feature dimensions.\n",
    "        @dim: input feature dimension (number of features per timestep)\n",
    "    '''\n",
    "    lengths = [len(s) for s in sequences]\n",
    "\n",
    "    nb_samples = len(sequences)\n",
    "    if maxlen is None:\n",
    "        maxlen = np.max(lengths)\n",
    "\n",
    "    x = (np.ones((nb_samples, maxlen, dim)) * value).astype(dtype)\n",
    "    for idx, s in enumerate(sequences):\n",
    "        if truncating == 'pre':\n",
    "            trunc = s[-maxlen:]\n",
    "        elif truncating == 'post':\n",
    "            trunc = s[:maxlen]\n",
    "        else:\n",
    "            raise ValueError(\"Truncating type '%s' not understood\" % padding)\n",
    "\n",
    "        if padding == 'post':\n",
    "            x[idx, :len(trunc)] = trunc\n",
    "        elif padding == 'pre':\n",
    "            x[idx, -len(trunc):] = trunc\n",
    "        else:\n",
    "            raise ValueError(\"Padding type '%s' not understood\" % padding)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'list'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/subleenkaur/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:107: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "/Users/subleenkaur/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:107: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(input_shape=(None, 6), stateful=True, units=128, return_sequences=True, batch_input_shape=(5, 100, 6...)`\n",
      "/Users/subleenkaur/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:113: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=3, activation=\"sigmoid\", input_dim=128)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seqs\n",
      "3\n",
      "0.693065\n",
      "(100.000 %) 0.683660\n",
      "seqs\n",
      "2\n",
      "==== Epoch: 0, Test AUC: 0.650000\n",
      "seqs\n",
      "3\n",
      "0.682026\n",
      "(100.000 %) 0.665668\n",
      "seqs\n",
      "2\n",
      "==== Epoch: 1, Test AUC: 0.700000\n",
      "seqs\n",
      "3\n",
      "0.674965\n",
      "(100.000 %) 0.651343\n",
      "seqs\n",
      "2\n",
      "==== Epoch: 2, Test AUC: 0.690000\n",
      "seqs\n",
      "3\n",
      "0.66871\n",
      "(100.000 %) 0.637414\n",
      "seqs\n",
      "2\n",
      "==== Epoch: 3, Test AUC: 0.690000\n",
      "seqs\n",
      "3\n",
      "0.662744\n",
      "(100.000 %) 0.623193\n",
      "seqs\n",
      "2\n",
      "==== Epoch: 4, Test AUC: 0.690000\n",
      "seqs\n",
      "3\n",
      "0.656918\n",
      "(100.000 %) 0.608650\n",
      "seqs\n",
      "2\n",
      "==== Epoch: 5, Test AUC: 0.690000\n",
      "seqs\n",
      "3\n",
      "0.651236\n",
      "(100.000 %) 0.594200\n",
      "seqs\n",
      "2\n",
      "==== Epoch: 6, Test AUC: 0.690000\n",
      "seqs\n",
      "3\n",
      "0.645803\n",
      "(100.000 %) 0.580488\n",
      "seqs\n",
      "2\n",
      "==== Epoch: 7, Test AUC: 0.690000\n",
      "seqs\n",
      "3\n",
      "0.640785\n",
      "(100.000 %) 0.567847\n",
      "seqs\n",
      "2\n",
      "==== Epoch: 8, Test AUC: 0.690000\n",
      "seqs\n",
      "3\n",
      "0.636309\n",
      "(100.000 %) 0.555735\n",
      "seqs\n",
      "2\n",
      "==== Epoch: 9, Test AUC: 0.690000\n",
      "seqs\n",
      "3\n",
      "0.632337\n",
      "(100.000 %) 0.543114\n",
      "seqs\n",
      "2\n",
      "==== Epoch: 10, Test AUC: 0.690000\n",
      "seqs\n",
      "3\n",
      "0.628699\n",
      "(100.000 %) 0.529307\n",
      "seqs\n",
      "2\n",
      "==== Epoch: 11, Test AUC: 0.690000\n",
      "seqs\n",
      "3\n",
      "0.625226\n",
      "(100.000 %) 0.514128\n",
      "seqs\n",
      "2\n",
      "==== Epoch: 12, Test AUC: 0.690000\n",
      "seqs\n",
      "3\n",
      "0.621815\n",
      "(100.000 %) 0.497659\n",
      "seqs\n",
      "2\n",
      "==== Epoch: 13, Test AUC: 0.690000\n",
      "seqs\n",
      "3\n",
      "0.618414\n",
      "(100.000 %) 0.480143\n",
      "seqs\n",
      "2\n",
      "==== Epoch: 14, Test AUC: 0.690000\n",
      "seqs\n",
      "3\n",
      "0.615005\n",
      "(100.000 %) 0.461937\n",
      "seqs\n",
      "2\n",
      "==== Epoch: 15, Test AUC: 0.690000\n",
      "seqs\n",
      "3\n",
      "0.611585\n",
      "(100.000 %) 0.443469\n",
      "seqs\n",
      "2\n",
      "==== Epoch: 16, Test AUC: 0.690000\n",
      "seqs\n",
      "3\n",
      "0.608163\n",
      "(100.000 %) 0.425165\n",
      "seqs\n",
      "2\n",
      "==== Epoch: 17, Test AUC: 0.710000\n",
      "seqs\n",
      "3\n",
      "0.604754\n",
      "(100.000 %) 0.407395\n",
      "seqs\n",
      "2\n",
      "==== Epoch: 18, Test AUC: 0.710000\n",
      "seqs\n",
      "3\n",
      "0.601374\n",
      "(100.000 %) 0.390437\n",
      "seqs\n",
      "2\n",
      "==== Epoch: 19, Test AUC: 0.710000\n",
      "seqs\n",
      "3\n",
      "0.598041\n",
      "(100.000 %) 0.374467\n",
      "seqs\n",
      "2\n",
      "==== Epoch: 20, Test AUC: 0.710000\n",
      "seqs\n",
      "3\n",
      "0.594772\n",
      "(100.000 %) 0.359574\n",
      "seqs\n",
      "2\n",
      "==== Epoch: 21, Test AUC: 0.710000\n",
      "seqs\n",
      "3\n",
      "0.591585\n",
      "(100.000 %) 0.345766\n",
      "seqs\n",
      "2\n",
      "==== Epoch: 22, Test AUC: 0.710000\n",
      "seqs\n",
      "3\n",
      "0.588495\n",
      "(100.000 %) 0.332972\n",
      "seqs\n",
      "2\n",
      "==== Epoch: 23, Test AUC: 0.710000\n",
      "seqs\n",
      "3\n",
      "0.585515\n",
      "(100.000 %) 0.321052\n",
      "seqs\n",
      "2\n",
      "==== Epoch: 24, Test AUC: 0.710000\n",
      "seqs\n",
      "3\n",
      "0.58265\n",
      "(100.000 %) 0.309818\n",
      "seqs\n",
      "2\n",
      "==== Epoch: 25, Test AUC: 0.720000\n",
      "seqs\n",
      "3\n",
      "0.579897\n",
      "(100.000 %) 0.299067\n",
      "seqs\n",
      "2\n",
      "==== Epoch: 26, Test AUC: 0.710000\n",
      "seqs\n",
      "3\n",
      "0.577248\n",
      "(100.000 %) 0.288609\n",
      "seqs\n",
      "2\n",
      "==== Epoch: 27, Test AUC: 0.770000\n",
      "seqs\n",
      "3\n",
      "0.574691\n",
      "(100.000 %) 0.278288\n",
      "seqs\n",
      "2\n",
      "==== Epoch: 28, Test AUC: 0.780000\n",
      "seqs\n",
      "3\n",
      "0.57221\n",
      "(100.000 %) 0.267979\n",
      "seqs\n",
      "2\n",
      "==== Epoch: 29, Test AUC: 0.770000\n",
      "seqs\n",
      "3\n",
      "0.569792\n",
      "(100.000 %) 0.257585\n",
      "seqs\n",
      "2\n",
      "==== Epoch: 30, Test AUC: 0.770000\n",
      "seqs\n",
      "3\n",
      "0.567423\n",
      "(100.000 %) 0.247026\n",
      "seqs\n",
      "2\n",
      "==== Epoch: 31, Test AUC: 0.770000\n",
      "seqs\n",
      "3\n",
      "0.565089\n",
      "(100.000 %) 0.236231\n",
      "seqs\n",
      "2\n",
      "==== Epoch: 32, Test AUC: 0.770000\n",
      "seqs\n",
      "3\n",
      "0.562774\n",
      "(100.000 %) 0.225129\n",
      "seqs\n",
      "2\n",
      "==== Epoch: 33, Test AUC: 0.770000\n",
      "seqs\n",
      "3\n",
      "0.560481\n",
      "(100.000 %) 0.213670\n",
      "seqs\n",
      "2\n",
      "==== Epoch: 34, Test AUC: 0.770000\n",
      "seqs\n",
      "3\n",
      "0.558193\n",
      "(100.000 %) 0.201847\n",
      "seqs\n",
      "2\n",
      "==== Epoch: 35, Test AUC: 0.770000\n",
      "seqs\n",
      "3\n",
      "0.555908\n",
      "(100.000 %) 0.189698\n",
      "seqs\n",
      "2\n",
      "==== Epoch: 36, Test AUC: 0.800000\n",
      "seqs\n",
      "3\n",
      "0.553623\n",
      "(100.000 %) 0.177210\n",
      "seqs\n",
      "2\n",
      "==== Epoch: 37, Test AUC: 0.780000\n",
      "seqs\n",
      "3\n",
      "0.551318\n",
      "(100.000 %) 0.164289\n",
      "seqs\n",
      "2\n",
      "==== Epoch: 38, Test AUC: 0.770000\n",
      "seqs\n",
      "3\n",
      "0.548994\n",
      "(100.000 %) 0.151089\n",
      "seqs\n",
      "2\n",
      "==== Epoch: 39, Test AUC: 0.770000\n",
      "seqs\n",
      "3\n",
      "0.54665\n",
      "(100.000 %) 0.137675\n",
      "seqs\n",
      "2\n",
      "==== Epoch: 40, Test AUC: 0.770000\n",
      "seqs\n",
      "3\n",
      "0.54427\n",
      "(100.000 %) 0.124207\n",
      "seqs\n",
      "2\n",
      "==== Epoch: 41, Test AUC: 0.770000\n",
      "seqs\n",
      "3\n",
      "0.541889\n",
      "(100.000 %) 0.110974\n",
      "seqs\n",
      "2\n",
      "==== Epoch: 42, Test AUC: 0.770000\n",
      "seqs\n",
      "3\n",
      "0.539501\n",
      "(100.000 %) 0.098823\n",
      "seqs\n",
      "2\n",
      "==== Epoch: 43, Test AUC: 0.760000\n",
      "seqs\n",
      "3\n",
      "0.537223\n",
      "(100.000 %) 0.087600\n",
      "seqs\n",
      "2\n",
      "==== Epoch: 44, Test AUC: 0.790000\n",
      "seqs\n",
      "3\n",
      "0.534749\n",
      "(100.000 %) 0.078315\n",
      "seqs\n",
      "2\n",
      "==== Epoch: 45, Test AUC: 0.770000\n",
      "seqs\n",
      "3\n",
      "0.532871\n",
      "(100.000 %) 0.071807\n",
      "seqs\n",
      "2\n",
      "==== Epoch: 46, Test AUC: 0.770000\n",
      "seqs\n",
      "3\n",
      "0.529927\n",
      "(100.000 %) 0.073238\n",
      "seqs\n",
      "2\n",
      "==== Epoch: 47, Test AUC: 0.770000\n",
      "seqs\n",
      "3\n",
      "0.528933\n",
      "(100.000 %) 0.060289\n",
      "seqs\n",
      "2\n",
      "==== Epoch: 48, Test AUC: 0.750000\n",
      "seqs\n",
      "3\n",
      "0.526101\n",
      "(100.000 %) 0.054133\n",
      "seqs\n",
      "2\n",
      "==== Epoch: 49, Test AUC: 0.770000\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
